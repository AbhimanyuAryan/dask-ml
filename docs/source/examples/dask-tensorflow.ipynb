{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "from dask import delayed\n",
    "from dask_tensorflow import start_tensorflow\n",
    "from distributed import Client, progress\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dd.read_parquet(\"susy/train\")\n",
    "test = dd.read_parquet(\"susy/test\")\n",
    "\n",
    "y_train = train['0'] \n",
    "X_train = train.drop('0', axis=1)\n",
    "\n",
    "y_test = test['0']\n",
    "X_test = test.drop('0', axis=1)\n",
    "\n",
    "X_train, y_train, X_test, y_test = client.persist([X_train, y_train, X_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_spec, dask_spec = start_tensorflow(client, ps=2, worker=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.server_lib.ClusterSpec at 0x121ccdac8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ps': ['tcp://127.0.0.1:53325', 'tcp://127.0.0.1:53327'],\n",
       " 'worker': ['tcp://127.0.0.1:53333',\n",
       "  'tcp://127.0.0.1:53336',\n",
       "  'tcp://127.0.0.1:53335',\n",
       "  'tcp://127.0.0.1:53338']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(server):\n",
    "    worker_device = \"/job:%s/task:%d\" % (server.server_def.job_name,\n",
    "                                         server.server_def.task_index)\n",
    "    task_index = server.server_def.task_index\n",
    "    is_chief = task_index == 0\n",
    "\n",
    "    with tf.device(tf.train.replica_device_setter(\n",
    "                      worker_device=worker_device,\n",
    "                      ps_device=\"/job:ps/cpu:0\",\n",
    "                      cluster=tf_spec)):\n",
    "\n",
    "        global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "\n",
    "        # Variables of the hidden layer\n",
    "        hid_w = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [IMAGE_PIXELS * IMAGE_PIXELS, hidden_units],\n",
    "                stddev=1.0 / IMAGE_PIXELS),\n",
    "            name=\"hid_w\")\n",
    "        hid_b = tf.Variable(tf.zeros([hidden_units]), name=\"hid_b\")\n",
    "\n",
    "        # Variables of the softmax layer\n",
    "        sm_w = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [hidden_units, 10],\n",
    "                stddev=1.0 / math.sqrt(hidden_units)),\n",
    "            name=\"sm_w\")\n",
    "        sm_b = tf.Variable(tf.zeros([10]), name=\"sm_b\")\n",
    "\n",
    "        # Ops: located on the worker specified with task_index\n",
    "        x = tf.placeholder(tf.float32, [None, IMAGE_PIXELS * IMAGE_PIXELS])\n",
    "        y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "        hid_lin = tf.nn.xw_plus_b(x, hid_w, hid_b)\n",
    "        hid = tf.nn.relu(hid_lin)\n",
    "\n",
    "        y = tf.nn.softmax(tf.nn.xw_plus_b(hid, sm_w, sm_b))\n",
    "        cross_entropy = -tf.reduce_sum(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))\n",
    "\n",
    "        opt = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "        if sync_replicas:\n",
    "            if replicas_to_aggregate is None:\n",
    "                replicas_to_aggregate = num_workers\n",
    "            else:\n",
    "                replicas_to_aggregate = replicas_to_aggregate\n",
    "\n",
    "            opt = tf.train.SyncReplicasOptimizer(\n",
    "                      opt,\n",
    "                      replicas_to_aggregate=replicas_to_aggregate,\n",
    "                      total_num_replicas=num_workers,\n",
    "                      name=\"mnist_sync_replicas\")\n",
    "\n",
    "        train_step = opt.minimize(cross_entropy, global_step=global_step)\n",
    "\n",
    "        if sync_replicas:\n",
    "            local_init_op = opt.local_step_init_op\n",
    "            if is_chief:\n",
    "                local_init_op = opt.chief_init_op\n",
    "\n",
    "            ready_for_local_init_op = opt.ready_for_local_init_op\n",
    "\n",
    "            # Initial token and chief queue runners required by the sync_replicas mode\n",
    "            chief_queue_runner = opt.get_chief_queue_runner()\n",
    "            sync_init_op = opt.get_init_tokens_op()\n",
    "\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        train_dir = tempfile.mkdtemp()\n",
    "\n",
    "        if sync_replicas:\n",
    "          sv = tf.train.Supervisor(\n",
    "              is_chief=is_chief,\n",
    "              logdir=train_dir,\n",
    "              init_op=init_op,\n",
    "              local_init_op=local_init_op,\n",
    "              ready_for_local_init_op=ready_for_local_init_op,\n",
    "              recovery_wait_secs=1,\n",
    "              global_step=global_step)\n",
    "        else:\n",
    "          sv = tf.train.Supervisor(\n",
    "              is_chief=is_chief,\n",
    "              logdir=train_dir,\n",
    "              init_op=init_op,\n",
    "              recovery_wait_secs=1,\n",
    "              global_step=global_step)\n",
    "\n",
    "        sess_config = tf.ConfigProto(\n",
    "            allow_soft_placement=True,\n",
    "            log_device_placement=False,\n",
    "            device_filters=[\"/job:ps\", \"/job:worker/task:%d\" % task_index])\n",
    "\n",
    "        # The chief worker (task_index==0) session will prepare the session,\n",
    "        # while the remaining workers will wait for the preparation to complete.\n",
    "        if is_chief:\n",
    "          print(\"Worker %d: Initializing session...\" % task_index)\n",
    "        else:\n",
    "          print(\"Worker %d: Waiting for session to be initialized...\" %\n",
    "                task_index)\n",
    "\n",
    "        sess = sv.prepare_or_wait_for_session(server.target, config=sess_config)\n",
    "\n",
    "        if sync_replicas and is_chief:\n",
    "          # Chief worker will start the chief queue runner and call the init op.\n",
    "          sess.run(sync_init_op)\n",
    "          sv.start_queue_runners(sess, [chief_queue_runner])\n",
    "\n",
    "        return sess, x, y_, train_step, global_step, cross_entropy\n",
    "\n",
    "\n",
    "def ps_task():\n",
    "    with local_client() as c:\n",
    "        c.worker.tensorflow_server.join()\n",
    "\n",
    "\n",
    "def scoring_task():\n",
    "    with local_client() as c:\n",
    "        # Scores Channel\n",
    "        scores = c.channel('scores', maxlen=10)\n",
    "\n",
    "        # Make Model\n",
    "        server = c.worker.tensorflow_server\n",
    "        sess, _, _, _, _, cross_entropy = model(c.worker.tensorflow_server)\n",
    "\n",
    "        # Testing Data\n",
    "        from tensorflow.examples.tutorials.mnist import input_data\n",
    "        mnist = input_data.read_data_sets('/tmp/mnist-data', one_hot=True)\n",
    "        test_data = {x: mnist.validation.images,\n",
    "                     y_: mnist.validation.labels}\n",
    "\n",
    "        # Main Loop\n",
    "        while True:\n",
    "            score = sess.run(cross_entropy, feed_dict=test_data)\n",
    "            scores.append(float(score))\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "\n",
    "def worker_task():\n",
    "    with local_client() as c:\n",
    "        scores = c.channel('scores')\n",
    "        num_workers = replicas_to_aggregate = len(dask_spec['worker'])\n",
    "\n",
    "        server = c.worker.tensorflow_server\n",
    "        queue = c.worker.tensorflow_queue\n",
    "\n",
    "        # Make model\n",
    "        sess, x, y_, train_step, global_step, _= model(c.worker.tensorflow_server)\n",
    "\n",
    "        # Main loop\n",
    "        while not scores or scores.data[-1] > 1000:\n",
    "            try:\n",
    "                batch = queue.get(timeout=0.5)\n",
    "            except Empty:\n",
    "                continue\n",
    "\n",
    "            train_data = {x: batch[0],\n",
    "                          y_: batch[1]}\n",
    "\n",
    "            sess.run([train_step, global_step], feed_dict=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
